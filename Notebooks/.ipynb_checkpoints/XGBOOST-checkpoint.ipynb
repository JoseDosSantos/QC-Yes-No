{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Module Import\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-f93c9c091675>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-f93c9c091675>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    import ..\\Classification.config as cfg\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Classification.config as cfg\n",
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "import spacy\n",
    "import pickle\n",
    "import time\n",
    "import operator\n",
    "from nltk.util import ngrams\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Defining the string cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    #return string\n",
    "    clean_string = string.replace(u'\\xa0', u' ')\n",
    "    clean_string = re.sub(r'\\d+', ' number ', clean_string)\n",
    "    clean_string = re.sub(r'\\n', ' ', clean_string)\n",
    "    clean_string = re.sub(r'Ä', 'Ae', clean_string)\n",
    "    clean_string = re.sub(r'ä', 'ae', clean_string)\n",
    "    clean_string = re.sub(r'Ö', 'Oe', clean_string)\n",
    "    clean_string = re.sub(r'ö', 'oe', clean_string)\n",
    "    clean_string = re.sub(r'Ü', 'Ue', clean_string)\n",
    "    clean_string = re.sub(r'ü', 'ue', clean_string)\n",
    "    clean_string = re.sub(r'ß', 'ss', clean_string)\n",
    "    clean_string = re.sub(r'°', ' Grad ', clean_string)\n",
    "    clean_string = re.sub(r'24/7', 'immer', clean_string)\n",
    "    clean_string = re.sub(r'/', ' ', clean_string)\n",
    "    clean_string = re.sub(r'%', ' Prozent ', clean_string)\n",
    "    clean_string = re.sub(r'[Zz][Bb]', 'zum Beispiel', clean_string)\n",
    "    clean_string = re.sub(r'[Dd][Hh]', 'das heißt', clean_string)\n",
    "    clean_string = re.sub(r'[Bb][Ss][Pp][Ww]', 'beispielsweise', clean_string)\n",
    "    clean_string = re.sub(r'[Hh]allo', '', clean_string)\n",
    "    clean_string = re.sub(r'[Hh]i', '', clean_string)\n",
    "    clean_string = re.sub(r'[Hh]ey', '', clean_string)\n",
    "    clean_string = re.sub(r'[Gg]uten\\s[Mm]orgen', '', clean_string)\n",
    "    clean_string = re.sub(r'[Gg]uten\\s[Aa]bend', '', clean_string)\n",
    "    \n",
    "    clean_string = re.sub(r'(\\([^)]*\\))', ' ', clean_string)\n",
    "    clean_string = re.sub(r'\"', '', clean_string)\n",
    "    clean_string = re.sub(r'\\+', '', clean_string)\n",
    "    clean_string = re.sub(r'-', '', clean_string)\n",
    "    clean_string = re.sub(r',', ' ', clean_string)\n",
    "    clean_string = re.sub(r'\\^', '', clean_string)\n",
    "    clean_string = re.sub(r'\\'', '', clean_string)\n",
    "    clean_string = re.sub(r'`', '', clean_string)\n",
    "    clean_string = re.sub(r'´', '', clean_string)\n",
    "\n",
    "\n",
    "    clean_string = re.sub(r'\\'', '', clean_string)\n",
    "    clean_string = re.sub(r'\\.', '', clean_string)\n",
    "    clean_string = re.sub(r'\\s{2,}', ' ', clean_string)\n",
    "    clean_string = re.sub(r'\\s(?=\\?)', ' ', clean_string)\n",
    "    clean_string = re.sub(r'\\?*(?=(?:\\?))', '', clean_string)\n",
    "    clean_string = clean_string.strip()\n",
    "    #bitte, danke, und, eigentlich, überhaupt, git, wirklich\n",
    "    return clean_string#.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Building the lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de')\n",
    "\n",
    "def lemmatizer(text):\n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30/30 Imported file C:\\Users\\Josef\\PycharmProjects\\QC-Yes-No\\Corpus\\Tweets\\questions\\output_1000_tweets_2018-09-22_17-18-48\\classified.csv. Total length: 5011)\n",
      "\n",
      "Import finished. Total length of data set: 5011\n",
      "Time taken: 35.0461630821228\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "data_set = []\n",
    "data_set_index = pd.DataFrame(columns=['File Name', 'Start', 'End', 'Size'])\n",
    "start_index = 0\n",
    "\n",
    "for i, file in enumerate(cfg.ALL_FILES):\n",
    "    file_count = len(cfg.ALL_FILES)\n",
    "    reader = csv.reader(open(file, 'r'), delimiter=';')\n",
    "\n",
    "    for line in reader:\n",
    "        try:\n",
    "            data_set.append([lemmatizer(clean(line[0])).lower(), line[1]])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    print(('({0}/{1} Imported file {2}. Total length: {3})'.format(i + 1, file_count, file, len(data_set))), end='\\r')\n",
    "    \n",
    "    data_set_index.loc[i] = [file, start_index, len(data_set) - 1, len(data_set) - 1 - start_index]\n",
    "    start_index = len(data_set)\n",
    "\n",
    "print('\\n\\nImport finished. Total length of data set: {}'.format(len(data_set)))\n",
    "\n",
    "data_set_frame = pd.DataFrame(data_set, columns =['Feature', 'Label'])\n",
    "\n",
    "print('Time taken:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Creating PosTag feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 41.44835591316223\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with open('Classification\\\\nltk_german_classifier_data.pickle', 'rb') as f:\n",
    "    tagger = pickle.load(f)\n",
    "    \n",
    "data_set_frame['PosTags'] = ''\n",
    "\n",
    "for i, line in enumerate(data_set_frame['Feature']):\n",
    "    sent = nltk.tokenize.WordPunctTokenizer().tokenize(line)\n",
    "    tag_line = []\n",
    "    for tag in tagger.tag(sent):\n",
    "        tag_line.append(tag[1])\n",
    "    data_set_frame.at[i, 'PosTags'] = tag_line\n",
    "    #print(('Tagged line {}'.format(i)), end='\\r')\n",
    "\n",
    "print('Time taken:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Building the feature bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bag of words. Amount of words: 5960\n",
      "Created bag of ngrams. Amount of ngrams: 19582\n",
      "Created bag of tags. Amount of tags: 45\n",
      "Time taken: 0.3869509696960449\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "words_bag = set(word for passage in data_set for word in nltk.tokenize.WordPunctTokenizer().tokenize(passage[0]))\n",
    "print('Created bag of words. Amount of words: {0}'.format(len(words_bag)))\n",
    "ngrams_bag = set(gram for passage in data_set for gram in ngrams(nltk.tokenize.WordPunctTokenizer().tokenize(passage[0]), 2))\n",
    "print('Created bag of ngrams. Amount of ngrams: {0}'.format(len(ngrams_bag)))\n",
    "tags_bag = set(tag for index, row in data_set_frame.iterrows() for tag in row['PosTags'])\n",
    "print('Created bag of tags. Amount of tags: {0}'.format(len(tags_bag)))\n",
    "print('Time taken:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Building the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('checked_list.pickle', 'rb') as f:\n",
    "    checked_rows = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "def evaluate(test_frame, predictions):\n",
    "    #test_frame = pd.DataFrame(y_com_test)\n",
    "    test_frame_local = deepcopy(test_frame)\n",
    "    test_frame_local.columns = ['Label']\n",
    "    test_frame_local['Prediction'] = preds\n",
    "    false_rows = []\n",
    "    \n",
    "    def find_dataset_location(index):\n",
    "        found = data_set_index.loc[(data_set_index['Start'] <= index) & (data_set_index['End'] >= index)]\n",
    "        found_info = found['File Name'].item().split('\\\\Corpus\\\\')[1]\n",
    "        found_type, found_file = found_info.split('\\\\')[0], found_info.split('\\\\')[2]\n",
    "        index_in_file = index - found['Start'].item() + 1\n",
    "        return found_type, found_file, index_in_file\n",
    "    \n",
    "    \n",
    "    for index, row in test_frame_local.iterrows():\n",
    "        i=1\n",
    "        if row['Prediction'] != row['Label']:\n",
    "            i+=1\n",
    "            loc = find_dataset_location(index)\n",
    "            false_rows.append([index, data_set[index][0], row['Label'], row['Prediction'], loc[0], loc[1], loc[2]])\n",
    "            \n",
    "    false_rows.sort(key=operator.itemgetter(0))\n",
    "    evaluation = pd.DataFrame(false_rows, columns=['Idx', 'Question', 'Label', 'Pred', 'Type', 'File', 'Line in File'])\n",
    "    display('Found {0} possibly wrongly labeled questions.'.format(len(evaluation.loc[~evaluation['Idx'].isin(checked_rows)])))\n",
    "    display(evaluation.loc[~evaluation['Idx'].isin(checked_rows)])\n",
    "    checked_rows.update(evaluation['Idx'].values)\n",
    "\n",
    "print('Time taken:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 Creating words based feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 141.10128474235535\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "fs_words= [([(word in nltk.tokenize.WordPunctTokenizer().tokenize(data[0])) for word in words_bag], data[1]) for data in data_set]\n",
    "bag_words = pd.DataFrame(fs_words)\n",
    "print('Time taken:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Creating data points for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.4101691246032715\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "x_word, y_word = bag_words.iloc[:,:-1],bag_words.iloc[:,-1]\n",
    "x_frame_word = pd.DataFrame(x_word[0].tolist(), columns = words_bag)\n",
    "x_word_train, x_word_test, y_word_train, y_word_test = train_test_split(x_frame_word, y_word, test_size=0.2)\n",
    "print('Time taken:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Training and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####          Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'NaiveBayesClassifier' has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b6bffcd4a0f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_most_informative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Naive Bayes: \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'NaiveBayesClassifier' has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.fit(x_train, y_train)\n",
    "classifier.show_most_informative_features()\n",
    "print('Naive Bayes: \\n', nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-nearest-Neigbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 80.75872254371643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9501495513459621"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "xg_class_word = xgb.XGBClassifier(max_depth=5, n_estimators=100, learning_rate=0.125, min_child_weight = 1, njobs=-1)\n",
    "xg_class_word.fit(x_word_train, y_word_train)\n",
    "preds = xg_class_word.predict(x_word_test)\n",
    "\n",
    "print('Time taken:', time.time() - start_time)\n",
    "\n",
    "display('Accuracy:', accuracy_score(preds, y_word_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Evaluating possible problematic questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Found 9 possibly wrongly labeled questions.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idx</th>\n",
       "      <th>Question</th>\n",
       "      <th>Label</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Type</th>\n",
       "      <th>File</th>\n",
       "      <th>Line in File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>schaut der laptop aus wie auf der bild ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>output_products_part_11</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2188</td>\n",
       "      <td>haben mein auch ein schoenen sonnenauf oder untergang fotografieren ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-08-21_17-02-43</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2667</td>\n",
       "      <td>seh ich aus wie einen auto ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-08-22_16-25-32</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2710</td>\n",
       "      <td>weiss noch jemand was ich damit vor haben ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-08-22_16-25-32</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3740</td>\n",
       "      <td>fuehrt mein eigentlich einen tagebuch oder so etwas aehnliches ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-09-10_23-44-03</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3747</td>\n",
       "      <td>wissen mein mutti oder der ex davon ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-09-10_23-44-03</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4190</td>\n",
       "      <td>ich haben was gut zu tun als sich abholen ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-09-11_13-29-40</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4252</td>\n",
       "      <td>gibst du bescheid wann ich mit druecken aufhoeren können ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-09-13_13-50-33</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4473</td>\n",
       "      <td>oder sollen ich sich vielleicht gar nicht so nennen ?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>output_1000_tweets_2018-09-18_01-29-15</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Idx                                                               Question Label Pred    Type                                    File  Line in File\n",
       "3   1261                               schaut der laptop aus wie auf der bild ?     1    0  Amazon                 output_products_part_11            61\n",
       "11  2188  haben mein auch ein schoenen sonnenauf oder untergang fotografieren ?     1    0  Tweets  output_1000_tweets_2018-08-21_17-02-43           204\n",
       "17  2667                                           seh ich aus wie einen auto ?     1    0  Tweets  output_1000_tweets_2018-08-22_16-25-32           116\n",
       "18  2710                            weiss noch jemand was ich damit vor haben ?     1    0  Tweets  output_1000_tweets_2018-08-22_16-25-32           159\n",
       "31  3740       fuehrt mein eigentlich einen tagebuch oder so etwas aehnliches ?     1    0  Tweets  output_1000_tweets_2018-09-10_23-44-03            11\n",
       "33  3747                                  wissen mein mutti oder der ex davon ?     1    0  Tweets  output_1000_tweets_2018-09-10_23-44-03            18\n",
       "37  4190                            ich haben was gut zu tun als sich abholen ?     1    0  Tweets  output_1000_tweets_2018-09-11_13-29-40           223\n",
       "38  4252             gibst du bescheid wann ich mit druecken aufhoeren können ?     1    0  Tweets  output_1000_tweets_2018-09-13_13-50-33            53\n",
       "42  4473                  oder sollen ich sich vielleicht gar nicht so nennen ?     1    0  Tweets  output_1000_tweets_2018-09-18_01-29-15            96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate(pd.DataFrame(y_word_test), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(checked_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('checked_list.pickle', 'wb') as f:\n",
    "    pickle.dump(checked_rows, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6.1 Creating ngrams of words based feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_ngrams = [([(gram in ngrams(nltk.tokenize.WordPunctTokenizer().tokenize(data[0]), 2)) for gram in ngrams_bag], data[1]) for data in data_set]\n",
    "bag_ngram = pd.DataFrame(fs_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Creating data points for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ngram, y_ngram = bag_ngram.iloc[:,:-1],bag_ngram.iloc[:,-1]\n",
    "x_frame_ngram = pd.DataFrame(x_ngram[0].tolist(), columns = ngrams_bag)\n",
    "x_ngram_train, x_ngram_test, y_ngram_train, y_ngram_test = train_test_split(x_frame_ngram, y_ngram, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class_ngram = xgb.XGBClassifier(max_depth=6, n_estimators=200, learning_rate=0.15, min_child_weight = 1, njobs=4)\n",
    "xg_class_ngram.fit(x_ngram_train, y_ngram_train)\n",
    "preds = xg_class_ngram.predict(x_ngram_test)\n",
    "accuracy_score(preds, y_ngram_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Creating postags based feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Classification\\\\nltk_german_classifier_data.pickle', 'rb') as f:\n",
    "    tagger = pickle.load(f)\n",
    "    \n",
    "data_set_frame = pd.DataFrame(data_set)\n",
    "data_set_frame['PosTags'] = ''\n",
    "for i, line in enumerate(data_set_frame[0]):\n",
    "    sent = nltk.tokenize.WordPunctTokenizer().tokenize(line)\n",
    "    tag_line = []\n",
    "    for tag in tagger.tag(sent):\n",
    "        tag_line.append(tag[1])\n",
    "    data_set_frame.at[i, 'PosTags'] = tag_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bag = set(tag for index, row in data_set_frame.iterrows() for tag in row['PosTags'])\n",
    "fs_pos= [([(tag in row['PosTags']) for tag in tag_bag], row[1]) for item, row in data_set_frame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_pos = pd.DataFrame(fs_pos)\n",
    "x_pos, y_pos = bag_pos.iloc[:,:-1],bag_pos.iloc[:,-1]\n",
    "x_frame_pos = pd.DataFrame(x_pos[0].tolist(), columns = tag_bag)\n",
    "x_pos_train, x_pos_test, y_pos_train, y_pos_test = train_test_split(x_frame_pos, y_pos, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class_pos = xgb.XGBClassifier(max_depth=6, n_estimators=125, learning_rate=0.125, min_child_weight = 1, njobs=4)\n",
    "xg_class_pos.fit(x_pos_train, y_pos_train)\n",
    "preds = xg_class_pos.predict(x_pos_test)\n",
    "accuracy_score(preds, y_pos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_frame_com = pd.concat([x_frame_pos, x_frame_word], axis=1)\n",
    "x_com_train, x_com_test, y_com_train, y_com_test = train_test_split(x_frame_com, y_pos, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class_com = xgb.XGBClassifier(max_depth=6, n_estimators=125, learning_rate=0.125, min_child_weight = 0.5, subsample = 0.5, njobs=4)\n",
    "xg_class_com.fit(x_com_train, y_com_train)\n",
    "preds = xg_class_com.predict(x_com_test)\n",
    "accuracy_score(preds, y_com_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = pd.DataFrame(y_com_test)\n",
    "test_frame.columns=['Label']\n",
    "test_frame['Prediction']=preds\n",
    "for index, row in test_frame.iterrows():\n",
    "    if row['Prediction'] != row['Label']:\n",
    "        print(data_set[index], 'Label:', row['Label'], 'Prediction:', row['Prediction'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds\n",
    "wrong = [(index, y_com_test[index])  for index in preds if preds[index] != y_com_test[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_2 = [(index, test['Pred'][index])  for index in test.index if test[1][index] != test['Pred'][index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "all_lists = list(pd.DataFrame(data_set)[0])\n",
    "test_string = ''\n",
    "\n",
    "for e,i in enumerate(all_lists):\n",
    "    test_string += ' '\n",
    "    test_string += i\n",
    "    if i.split().count('?') < 1:\n",
    "        print(i, e)\n",
    "test_string = test_string.split()\n",
    "\n",
    "for word in words_bag:\n",
    "    count[word] = test_string.count(word)\n",
    "import operator\n",
    "sorted_x = sorted(count.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(sorted_x)\n",
    "frame.set_index(0, inplace=True)\n",
    "display(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "test_frame = deepcopy(data_set_frame)\n",
    "test_frame['Feature_min'] = ''\n",
    "for index, row in test_frame.iterrows():\n",
    "    for word in row[0].rsplit():\n",
    "        if frame[1][word] > 10:\n",
    "            test_frame.at[index, 'Feature_min'] += (word + ' ')\n",
    "        test_frame.at[index, 'Feature_min'] = test_frame.at[index, 'Feature_min']\n",
    "    print(('Checked row: {}'.format(index)), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bag_min = set(word for word in words_bag if frame[1][word] > 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_words_min= [([(word in data[2].split()) for word in words_bag_min], data[1]) for index, data in test_frame.iterrows()]\n",
    "bag_words_min = pd.DataFrame(fs_words_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_word_min, y_word_min = bag_words_min.iloc[:,:-1],bag_words_min.iloc[:,-1]\n",
    "x_frame_word_min = pd.DataFrame(x_word_min[0].tolist(), columns = words_bag_min)\n",
    "x_word_min_train, x_word_min_test, y_word_min_train, y_word_min_test = train_test_split(x_frame_word_min, y_word_min, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class_word_min = xgb.XGBClassifier(max_depth=7, n_estimators=100, learning_rate=0.125, min_child_weight = 0.4, subsample=0.7, njobs=4)\n",
    "xg_class_word_min.fit(x_word_min_train, y_word_min_train)\n",
    "preds = xg_class_word_min.predict(x_word_min_test)\n",
    "accuracy_score(preds, y_word_min_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test1 =  {\n",
    " 'learning_rate':[0.125, 1.5],\n",
    " 'n_estimators':[75, 100],\n",
    " 'max_depth': [5, 6, 7],\n",
    " 'min_child_weight': [0.5, 1],\n",
    " 'subsample': [0.5, 1]}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate = 0.125,\n",
    "                                                      max_depth = 5,\n",
    "                                                      random_state= 10,\n",
    "                                                      min_child_weight = 1), \n",
    "param_grid = param_test1, n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.estimator.get_params()\n",
    "gsearch1.fit(np.array(x_word_min_train), np.array(y_word_min_train))\n",
    "\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(xg_class_word, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(30, 30))\n",
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "xgb.plot_tree(xg_class_word, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test1 =  {\n",
    " 'learning_rate':[0.125, 1.5],\n",
    " 'n_estimators':[75, 100, 125],\n",
    " 'max_depth': [4, 5, 6]}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate = 0.1,\n",
    "                                                      max_depth = 5,\n",
    "                                                      random_state= 10,\n",
    "                                                      min_child_weight = 1), \n",
    "param_grid = param_test1, n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.estimator.get_params()\n",
    "gsearch1.fit(np.array(x_word_train), np.array(y_word_train))\n",
    "\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x, y = bag_ngram.iloc[:,:-1],bag_ngram.iloc[:,-1]\n",
    "\n",
    "x_frame = pd.DataFrame(x[0].tolist(), columns = ngrams_bag)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_frame, y, test_size=0.2)#, random_state=20)\n",
    "\n",
    "xg_class = xgb.XGBClassifier(max_depth=6, n_estimators=100, learning_rate=0.1, min_child_weight = 1, njobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class.fit(x_train, y_train)\n",
    "preds = xg_class.predict(x_test)\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_ngram = [([(gram in ngrams(nltk.tokenize.WordPunctTokenizer().tokenize(data[0]), 2)) for gram in ngrams_bag], data[1]) for data in data_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_ngram = pd.DataFrame(fs_ngram)\n",
    "\n",
    "x, y = bag_ngram.iloc[:,:-1],bag_ngram.iloc[:,-1]\n",
    "\n",
    "x_frame = pd.DataFrame(x[0].tolist(), columns = ngrams_bag)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_frame, y, test_size=0.2)#, random_state=20)\n",
    "\n",
    "xg_class = xgb.XGBClassifier(max_depth=7, n_estimators=400, learning_rate=0.1, min_child_weight = 1, njobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class.fit(x_train, y_train)\n",
    "preds = xg_class.predict(x_test)\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_encoded = pd.DataFrame(fs_words)\n",
    "\n",
    "x, y = bag_encoded.iloc[:,:-1],bag_encoded.iloc[:,-1]\n",
    "\n",
    "x_frame = pd.DataFrame(x[0].tolist(), columns = words_bag)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "accuracy = []\n",
    "for i in range(15):\n",
    "    xg_class = xgb.XGBClassifier(max_depth=5, n_estimators=100, learning_rate=0.125, min_child_weight = 1, njobs=4)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_frame, y, test_size=0.2, random_state=i)\n",
    "    xg_class.fit(x_train, y_train)\n",
    "    preds = xg_class.predict(x_test)\n",
    "    accuracy.append(accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test1 =  {\n",
    " 'learning_rate':[0.05, 0.1, 0.15],\n",
    " 'n_estimators':[75, 100, 125],\n",
    " 'max_depth': [6, 7],\n",
    " 'min_child_weight': [1, 2]}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate = 0.1,\n",
    "                                                      max_depth = 5,\n",
    "                                                      random_state= 10,\n",
    "                                                      min_child_weight = 1), \n",
    "param_grid = param_test1, n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.estimator.get_params()\n",
    "gsearch1.fit(np.array(x_train), np.array(y_train))\n",
    "\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Pred']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [3,5, 10]\n",
    "esti = [50, 100, 300, 1000]\n",
    "learning_rate = [0.05, 0.2, 0.4]\n",
    "\n",
    "for d in depth:\n",
    "    for e in esti:\n",
    "        for l in learning_rate:\n",
    "            xg_class = xgb.XGBClassifier(max_depth=d, n_estimators=e, learning_rate=l)\n",
    "            xg_class.fit(x_train, y_train)\n",
    "            preds = xg_class.predict(x_test)\n",
    "            print('Depth:', d, 'Estimators:', e, 'Learning Rate:', l, 'Accuracy', accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)*937799043062201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = [(index, test['Pred'][index])  for index in test.index if test[1][index] != test['Pred'][index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_2 = [(index, test['Pred'][index])  for index in test.index if test[1][index] != test['Pred'][index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pred in wrong:\n",
    "    print(i, data_set[i], 'pred:', pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
